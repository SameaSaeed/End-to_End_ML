# -*- coding: utf-8 -*-
"""dask_data-preprocessing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11WNQ4nX7mgQBHuyZvcVvC5yum9ByC2SU
"""

!pip install dask --quiet

from google.colab import files
uploaded = files.upload()

import dask.dataframe as dd
import numpy as np
from pathlib import Path
import logging

# Set up logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger('data-processor')

def load_data(file_path):
    """Load data from a CSV file using Dask."""
    logger.info(f"Loading data from {file_path}")
    return dd.read_csv(file_path)

def fill_missing(df, column):
    """Fill missing values lazily using median for numeric or mode for categorical."""
    if np.issubdtype(df[column].dtype, np.number):
        median_value = df[column].median()
        df[column] = df[column].fillna(median_value)
        logger.info(f"Filling missing numeric column '{column}' with median (lazy)")
    else:
        # Approximate mode lazily
        mode_value = df[column].value_counts().idxmax()
        df[column] = df[column].fillna(mode_value)
        logger.info(f"Filling missing categorical column '{column}' with mode (lazy)")
    return df

def remove_outliers(df, column='price'):
    """Remove outliers using IQR method lazily."""
    q1 = df[column].quantile(0.25)
    q3 = df[column].quantile(0.75)
    iqr = q3 - q1
    lower = q1 - 1.5 * iqr
    upper = q3 + 1.5 * iqr

    logger.info("Removing outliers lazily using IQR")
    return df[(df[column] >= lower) & (df[column] <= upper)]

def clean_data(df):
    """Clean the dataset lazily."""
    logger.info("Starting cleaning process (lazy)")

    for column in df.columns:
        missing_count = df[column].isnull().sum().compute()
        if missing_count > 0:
            logger.info(f"Found {missing_count} missing values in column '{column}'")
            df = fill_missing(df, column)

    df = remove_outliers(df, 'price')
    return df

def process_data(input_file, output_file):
    """Full lazy data processing pipeline."""
    output_path = Path(output_file).parent
    output_path.mkdir(parents=True, exist_ok=True)

    df = load_data(input_file)

    # Correct way to log shape in Dask
    nrows = df.shape[0].compute()
    ncols = df.shape[1]
    logger.info(f"Loaded data with shape: ({nrows}, {ncols})")

    df_cleaned = clean_data(df)

    # Save lazily; compute only at write time
    df_cleaned.to_csv(output_file, single_file=True, index=False)
    logger.info(f"Saved processed data to {output_file}")

    return df_cleaned

if __name__ == "__main__":
    process_data(
        input_file="/content/raw/data.csv",
        output_file="/content/processed/cleaned_data.csv"
    )